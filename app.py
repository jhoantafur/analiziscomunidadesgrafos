import streamlit as st
import pandas as pd
import networkx as nx
import re
from pyvis.network import Network
import streamlit.components.v1 as components
import plotly.graph_objects as go

# ¬†Configuraci√≥n de la P√°gina y Estilo
st.set_page_config(
    page_title="An√°lisis Tem√°tico de Redes Sociales", page_icon="‚ú®", layout="wide"
)

# Estilo CSS para mejorar la apariencia de las m√©tricas y otros elementos
st.markdown(
    """
<style>
div[data-testid="metric-container"] {
    background-color: #ECF0F1;
    border: 1px solid #ECF0F1;
    padding: 15px;
    border-radius: 10px;
    text-align: center;
    color: #2C3E50;
}
.stSelectbox div[data-baseweb="select"] > div {
    background-color: #F8F9F9;
}
.st-emotion-cache-16txtl3 {
    padding-top: 2rem;
}
</style>
""",
    unsafe_allow_html=True,
)


# ¬†Funciones de Carga y Procesamiento
@st.cache_data
def load_and_prepare_data(file_path):
    """Carga los datos y realiza la preparaci√≥n inicial una sola vez."""
    try:
        df = pd.read_csv(file_path)
        for col in ["Account_Created", "Tweet_DateTime"]:
            df[col] = pd.to_datetime(df[col])

        brands = ["zara", "h&m", "primark", "shein", "asos"]
        df["brand"] = (
            df["FinalCleaned"]
            .str.findall(f'({"|".join(brands)})', flags=re.IGNORECASE)
            .str[0]
            .str.lower()
        )
        df["brand"] = df["brand"].fillna("Otra")

        df["mentions"] = df["Tweet_Content"].apply(
            lambda text: ",".join(re.findall(r"@(\w+)", str(text)))
        )
        return df
    except FileNotFoundError:
        return None


@st.cache_data
def build_graph(df_selection):
    """Construye un grafo a partir de una selecci√≥n del DataFrame."""
    G = nx.DiGraph()
    for _, row in df_selection.iterrows():
        author = str(row["User_Handle"]).lower()
        mentioned_users_str = row["mentions"]

        if isinstance(mentioned_users_str, str) and mentioned_users_str:
            mentioned_users = mentioned_users_str.split(",")
            for mentioned_user in mentioned_users:
                G.add_edge(author, str(mentioned_user).lower())
    return G


# ¬†Carga de Datos Principal
df_original = load_and_prepare_data("data/datos_finales_analisis.csv")

# Nombres de los t√≥picos para usar en todo el dashboard
nombres_topicos = {
    0: "T√≥pico #1: Reventa y Marketplaces",
    1: "T√≥pico #2: Novedades y Ofertas",
    2: "T√≥pico #3: Colaboraci√≥n H&M con BGYO",
    3: "T√≥pico #4: Tendencias y Rebajas",
    4: "T√≥pico #5: Opiniones y Comparativas",
    5: "T√≥pico #6: Compras Online",
    6: "T√≥pico #7: Contenido de Influencers",
}


# ¬†NAVEGACI√ìN PRINCIPAL EN LA BARRA LATERAL
st.sidebar.title("Navegaci√≥n del Proyecto")
page = st.sidebar.radio(
    "Selecciona una p√°gina:", ["P√°gina Principal", "Dashboard de An√°lisis"]
)
st.sidebar.markdown("")

# -----------------------------------------------------
# P√ÅGINA PRINCIPAL
# -----------------------------------------------------
if page == "P√°gina Principal":
    st.title(
        "Sistema de An√°lisis Tem√°tico en Redes Sociales Aplicando Teor√≠a de Grafos y Miner√≠a de Texto"
    )

    st.image(
        "https://pbs.twimg.com/profile_images/496666199720067072/ddlIRzoR_400x400.jpeg",
    )

    st.markdown(
        """
    Este proyecto representa la culminaci√≥n de un estudio sobre la din√°mica de las conversaciones en redes sociales.
    A trav√©s de la aplicaci√≥n de t√©cnicas avanzadas, hemos desarrollado un sistema capaz de:
    - **Extraer y procesar** vol√∫menes de datos textuales de un dataset predefinido en Kaggle.
    - **Identificar temas latentes** mediante modelado de t√≥picos (LDA).
    - **Construir y analizar redes de interacci√≥n** para detectar comunidades e influencers.

    El resultado es un dashboard interactivo que permite explorar estos hallazgos de manera intuitiva y visual.
    """
    )

    st.markdown("")

    st.subheader("Realizado por:")
    st.markdown(
        """
    - Yohan Camilo Botello Maldonado
    - David Torres Ovallos
    - Jhoan Sebastian Tafur Rodriguez
    """
    )

    st.caption("Para la asignatura **Aplicaciones Pr√°cticas de Teor√≠a de Grafos**")
    st.caption("Universidad Francisco de Paula Santander, 2025")


# -----------------------------------------------------
# P√ÅGINA DEL DASHBOARD DE AN√ÅLISIS
# -----------------------------------------------------
elif page == "Dashboard de An√°lisis":
    if df_original is None:
        st.error(
            "Error: No se encontr√≥ el archivo 'datos_finales_analisis.csv'. No se puede cargar el dashboard."
        )
        st.stop()

    # FILTROS DEL DASHBOARD (AHORA EN LA BARRA LATERAL)
    st.sidebar.header("Filtros del Dashboard")
    selected_brand = st.sidebar.selectbox(
        "Filtrar por Marca",
        options=["TODAS"] + sorted(df_original["brand"].unique().tolist()),
    )

    df_filtered = df_original.copy()
    if selected_brand != "TODAS":
        df_filtered = df_original[df_original["brand"] == selected_brand].copy()

    # T√çTULO DEL DASHBOARD
    st.title(f"‚ú® Dashboard de An√°lisis de Moda: {selected_brand.upper()}")
    st.markdown(f"An√°lisis interactivo basado en **{len(df_filtered):,}** tweets.")

    # PESTA√ëAS DE AN√ÅLISIS
    tab1, tab2, tab3, tab4 = st.tabs(
        [
            "Visi√≥n General üìà",
            "An√°lisis de T√≥picos üí¨",
            "Perfil de Comunidades üë•",
            "Visualizaci√≥n de Red üï∏Ô∏è",
        ]
    )

    with tab1:
        st.header("M√©tricas Clave de la Conversaci√≥n")
        st.markdown(
            "Un resumen cuantitativo de la selecci√≥n actual. Estos n√∫meros reflejan el volumen y la estructura de la conversaci√≥n."
        )
        col1, col2, col3, col4 = st.columns(4)
        col1.metric("Tweets Analizados", f"{len(df_filtered):,}")
        col2.metric("Usuarios √önicos", f"{df_filtered['User_Handle'].nunique():,}")
        G_filtered = build_graph(df_filtered)
        col3.metric("Interacciones (Menciones)", f"{G_filtered.number_of_edges():,}")
        density = nx.density(G_filtered) if G_filtered.number_of_nodes() > 1 else 0
        col4.metric("Densidad de la Red", f"{density:.4f}")
        st.caption(
            "La densidad mide cu√°n conectada est√° la red (0=ninguna conexi√≥n, 1=todos conectados con todos). Un valor bajo es normal en redes grandes."
        )
        st.subheader("Evoluci√≥n Temporal de la Conversaci√≥n")
        st.markdown(
            "Este gr√°fico muestra el volumen de tweets a lo largo del tiempo. Los picos pueden indicar eventos importantes, campa√±as o lanzamientos."
        )
        if not df_filtered.empty:
            tweets_por_dia = (
                df_filtered.set_index("Tweet_DateTime").resample("D").size()
            )
            st.line_chart(tweets_por_dia)
        else:
            st.warning("No hay datos para el periodo seleccionado.")

    with tab2:
        st.header("¬øDe qu√© se est√° hablando? (An√°lisis de T√≥picos)")
        st.markdown(
            "Aqu√≠ identificamos los temas de conversaci√≥n dominantes. El gr√°fico muestra qu√© temas son m√°s frecuentes en la selecci√≥n filtrada."
        )
        with st.expander("‚ÑπÔ∏è ¬øQu√© es el Modelado de T√≥picos?"):
            st.info(
                """El Modelado de T√≥picos (con LDA) es una t√©cnica de IA que analiza el texto para descubrir autom√°ticamente grupos de palabras que aparecen juntas con frecuencia. Cada grupo forma un "t√≥pico"."""
            )
        if not df_filtered.empty:
            topic_counts = df_filtered["topic"].map(nombres_topicos).value_counts()
            st.bar_chart(topic_counts)
        else:
            st.warning("No hay datos para mostrar.")

    with tab3:
        st.header("¬øQui√©nes est√°n hablando? (Perfil de Comunidades)")
        st.markdown(
            "Aqu√≠ puedes seleccionar una comunidad detectada para analizar su 'personalidad': sus temas preferidos y sus miembros m√°s relevantes."
        )
        if not df_filtered.empty:
            communities_in_data = sorted(
                df_filtered["community"].dropna().unique().astype(int)
            )
            if communities_in_data:
                selected_community = st.selectbox(
                    "Selecciona una Comunidad para perfilar:",
                    options=communities_in_data,
                )
                df_community = df_filtered[
                    df_filtered["community"] == selected_community
                ]
                st.subheader(f"Perfil de la Comunidad #{selected_community}")
                col1, col2 = st.columns([1, 2])
                with col1:
                    st.metric(
                        "N¬∫ de Miembros en la Selecci√≥n",
                        f"{df_community['User_Handle'].nunique():,}",
                    )
                    st.metric("N¬∫ de Tweets de la Comunidad", f"{len(df_community):,}")
                    st.markdown("**Miembros m√°s activos:**")
                    st.dataframe(
                        df_community["User_Handle"].value_counts().head(5),
                        use_container_width=True,
                    )
                with col2:
                    st.markdown("**Temas de inter√©s principales:**")
                    topic_dist = (
                        df_community["topic"]
                        .map(nombres_topicos)
                        .value_counts(normalize=True)
                    )
                    fig = go.Figure(
                        data=[
                            go.Pie(
                                labels=topic_dist.index,
                                values=topic_dist.values,
                                hole=0.3,
                                textinfo="label+percent",
                            )
                        ]
                    )
                    fig.update_layout(showlegend=False, margin=dict(t=0, b=0, l=0, r=0))
                    st.plotly_chart(fig, use_container_width=True)
            else:
                st.warning("No hay comunidades para analizar en la selecci√≥n actual.")
        else:
            st.warning("No hay datos para mostrar.")

    with tab4:
        st.header("Mapa Interactivo de la Red")
        st.markdown(
            "Visualizaci√≥n interactiva del grafo de interacciones. Cada punto (nodo) es un usuario y cada l√≠nea (arista) es una menci√≥n."
        )
        with st.expander("‚ÑπÔ∏è ¬øC√≥mo interpretar este grafo?"):
            st.info(
                """* **Nodos (C√≠rculos):** Representan a los usuarios.
* **Tama√±o del Nodo:** Cuanto m√°s grande es el nodo, m√°s veces ha sido mencionado (mayor influencia).
* **L√≠neas (Aristas):** Muestran una menci√≥n de un usuario a otro.
* **Interactividad:** Puedes hacer zoom, arrastrar los nodos y pasar el rat√≥n sobre ellos para ver sus nombres."""
            )

        if not df_filtered.empty:
            G_vis = build_graph(df_filtered)

            if G_vis.number_of_nodes() > 0:
                G_display = None
                NODE_LIMIT = 200

                if G_vis.number_of_nodes() > NODE_LIMIT:
                    st.warning(
                        f"El grafo es muy grande ({G_vis.number_of_nodes()} nodos). Se mostrar√° un subgrafo centrado en los {NODE_LIMIT} nodos m√°s mencionados."
                    )

                    # 1. Obtenemos los N nodos m√°s mencionados (los m√°s importantes)
                    top_nodes_by_mentions = sorted(
                        G_vis.in_degree, key=lambda x: x[1], reverse=True
                    )[:NODE_LIMIT]
                    top_nodes_names = {name for name, degree in top_nodes_by_mentions}

                    # 2. Creamos un nuevo grafo vac√≠o
                    G_display = nx.DiGraph()

                    # 3. Recorremos TODAS las aristas del grafo original
                    # y a√±adimos solo aquellas que apuntan a nuestros nodos importantes.
                    for u, v in G_vis.edges():
                        if v in top_nodes_names:
                            G_display.add_edge(u, v)
                else:
                    G_display = G_vis

                if G_display and G_display.number_of_nodes() > 0:
                    # Asignar tama√±o a los nodos basado en cu√°ntas veces fueron mencionados
                    degrees = dict(G_display.in_degree())
                    for node in G_display.nodes():
                        size = degrees.get(node, 0)
                        G_display.nodes[node]["size"] = size * 3 + 15

                    # CONFIGURACI√ìN DE LA VISUALIZACI√ìN
                    net = Network(
                        height="750px",
                        width="100%",
                        bgcolor="#FFFFFF",
                        font_color="#333333",
                        cdn_resources="in_line",
                        directed=True,
                    )

                    # A√±adimos opciones de f√≠sica para mejorar el layout
                    net.set_options(
                        """
                    var options = {
                      "physics": {
                        "forceAtlas2Based": {
                          "gravitationalConstant": -50,
                          "centralGravity": 0.01,
                          "springLength": 230,
                          "springConstant": 0.08
                        },
                        "minVelocity": 0.75,
                        "solver": "forceAtlas2Based"
                      }
                    }
                    """
                    )

                    net.from_nx(G_display)

                    try:
                        html_content = net.generate_html(name="graph.html", local=True)
                        components.html(html_content, height=770, scrolling=True)
                    except Exception as e:
                        st.error(f"Error al generar el grafo: {e}")
                else:
                    st.warning(
                        "No se encontraron interacciones para los filtros seleccionados."
                    )
            else:
                st.warning(
                    "No hay interacciones (menciones) en la selecci√≥n actual para dibujar un grafo."
                )
        else:
            st.warning("No hay datos para visualizar.")
